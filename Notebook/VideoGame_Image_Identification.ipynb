{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EFBdeT8P2bBB"
      },
      "outputs": [],
      "source": [
        "!pip install -q yt-dlp split-folders opencv-python-headless tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow pillow matplotlib seaborn"
      ],
      "metadata": {
        "id": "MJeqcNnh3cn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os,random,json,math,shlex,subprocess\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import shutil"
      ],
      "metadata": {
        "id": "NYcE3ZlZ3rHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "Pvnj54o84IFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tensorflow Version: \", tf.__version__)\n",
        "tf.config.list_physical_devices('GPU')"
      ],
      "metadata": {
        "id": "zN06YbYu4fIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = \"./content/game_classifier\"\n",
        "raw_video_dir = os.path.join(root, \"videos\")\n",
        "frames_dir = os.path.join(root, \"frames\")\n",
        "dataset_dir = os.path.join(root, \"dataset\")\n",
        "models_dir = os.path.join(root, \"models\")\n",
        "for d in [raw_video_dir, frames_dir, dataset_dir, models_dir]:\n",
        "  os.makedirs(d, exist_ok=True)"
      ],
      "metadata": {
        "id": "7IPn1SId4kZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip frame_file.zip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "82YAbPuSC29k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE=  224\n",
        "BATCH_SIZE = 32\n",
        "random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "Nha9T0y65VSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "games = {\n",
        "    \"gta5\": [\"https://www.youtube.com/watch?v=K89JWVEDmV0&list=WL&index=8\",\n",
        "            \"https://www.youtube.com/watch?v=BiZtze2u2TA\"],\n",
        "    \"indiana_jones\": [\"https://www.youtube.com/watch?v=8vuxip2nO-M&list=WL&index=9\",\n",
        "                     \"https://www.youtube.com/watch?v=0ciyN9mgMFs\",\n",
        "                     \"https://www.youtube.com/watch?v=lDo6AkgaAJs\"],\n",
        "    \"tomb_raider\": [\"https://www.youtube.com/watch?v=cqGCtwxMuWQ&list=WL&index=7\",\n",
        "                   \"https://www.youtube.com/watch?v=XHtTcebsQcE\",\n",
        "                   \"https://www.youtube.com/watch?v=J7EPtPmt62c\"],\n",
        "    \"spiderman\": [\"https://www.youtube.com/watch?v=fAnIUbnOekA\"]\n",
        "}\n",
        "\n",
        "step_seconds = {\n",
        "    \"gta5\": 4,\n",
        "    \"indiana_jones\": 3,\n",
        "    \"tomb_raider\": 4,\n",
        "    \"spiderman\": 4\n",
        "}\n",
        "\n",
        "print(\"Games Registered: \", list(games.keys()))"
      ],
      "metadata": {
        "id": "eIE7lgAX5qve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yt_dlp\n",
        "def download_videos(url, out_path):\n",
        "  os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
        "  ydl_opt = {\n",
        "      'outtmpl': out_path,\n",
        "      'format': 'best[ext=mp4]/best'\n",
        "  }\n",
        "  try:\n",
        "    with yt_dlp.YoutubeDL(ydl_opt) as ydl:\n",
        "      ydl.download([url])\n",
        "    return True\n",
        "  except Exception as e:\n",
        "    print(\"download Failed:\", e)\n",
        "    return False"
      ],
      "metadata": {
        "id": "a2zA8OV7637a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for game, urls in games.items():\n",
        "    game_dir = os.path.join(raw_video_dir, game)\n",
        "    os.makedirs(game_dir, exist_ok=True)\n",
        "\n",
        "    for idx, url in enumerate(urls):\n",
        "        out_vid = os.path.join(game_dir, f\"{game}_{idx}.mp4\")\n",
        "\n",
        "        if os.path.exists(out_vid):\n",
        "            print(f\"{out_vid} already exists\")\n",
        "            continue\n",
        "\n",
        "        print(\"downloading\", out_vid)\n",
        "        ok = download_videos(url, out_vid)\n",
        "\n",
        "        if not ok:\n",
        "            print(f\"failed to download {url}\")\n",
        "        else:\n",
        "            print(\"Saved:\", out_vid)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mqT8dwxg8Ju0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_frames_for_game(game_name, video_path, out_dir, step_seconds=4, max_frames=None):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Cannot open video:\", video_path)\n",
        "        return 0\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
        "    step_frames = max(1, int(round(fps * step_seconds)))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)\n",
        "    saved = 0\n",
        "    frame_idx = 0\n",
        "    video_name = Path(video_path).stem\n",
        "\n",
        "    pbar = tqdm(total=total_frames, desc=f\"Extracting {game_name} | {video_name}\", unit=\"fr\")\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frame_idx % step_frames == 0:\n",
        "            out_path = os.path.join(\n",
        "                out_dir,\n",
        "                f\"{game_name}_{video_name}_{saved:05d}.jpg\"\n",
        "            )\n",
        "            cv2.imwrite(out_path, frame)\n",
        "            saved += 1\n",
        "\n",
        "            if max_frames and saved >= max_frames:\n",
        "                break\n",
        "\n",
        "        frame_idx += 1\n",
        "        pbar.update(1)\n",
        "\n",
        "    pbar.close()\n",
        "    cap.release()\n",
        "\n",
        "    print(f\"Saved {saved} frames from {video_name}\")\n",
        "    return saved\n",
        "\n",
        "for game in games.keys():\n",
        "    game_video_dir = os.path.join(raw_video_dir, game)\n",
        "    out_folder = os.path.join(frames_dir, game)\n",
        "    os.makedirs(out_folder, exist_ok=True)\n",
        "    video_files = sorted(Path(game_video_dir).glob(\"*.mp4\"))\n",
        "\n",
        "    if len(video_files) == 0:\n",
        "        print(f\"No videos found for {game}, skipping.\")\n",
        "        continue\n",
        "\n",
        "    existing_frames = len(list(Path(out_folder).glob(\"*.jpg\")))\n",
        "    if existing_frames > 50:\n",
        "        print(f\"Frames for {game} already exist ({existing_frames}), skipping extraction.\")\n",
        "        continue\n",
        "\n",
        "    ss = step_seconds.get(game, 4)\n",
        "    print(f\"\\nExtracting frames for {game} | step_seconds={ss}\")\n",
        "\n",
        "    for vid in video_files:\n",
        "        extract_frames_for_game(\n",
        "            game_name=game,\n",
        "            video_path=str(vid),\n",
        "            out_dir=out_folder,\n",
        "            step_seconds=ss\n",
        "        )"
      ],
      "metadata": {
        "id": "vI-M0_b89BeX",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "counts = {}\n",
        "for g in games.keys():\n",
        "    folder = os.path.join(frames_dir, g)\n",
        "    n = len(list(Path(folder).glob(\"*.jpg\")))\n",
        "    counts[g] = n\n",
        "print(\"Frame counts:\", counts)\n",
        "\n",
        "first = list(games.keys())[0]\n",
        "sample_files = list(Path(os.path.join(frames_dir, first)).glob(\"*.jpg\"))[:6]\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12,6))\n",
        "for i,f in enumerate(sample_files):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    img = Image.open(f).convert(\"RGB\").resize((320,180))\n",
        "    plt.imshow(img); plt.axis('off')\n",
        "plt.suptitle(first); plt.show()"
      ],
      "metadata": {
        "id": "z_REla-uFQWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.rmtree(\"content/game_classifier/dataset\")"
      ],
      "metadata": {
        "id": "bRFLOmJAQyqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET = 450\n",
        "frames_dir = Path(frames_dir)\n",
        "for game in frames_dir.iterdir():\n",
        "    imgs = list(game.glob(\"*.jpg\"))\n",
        "    if len(imgs) > TARGET:\n",
        "        remove = random.sample(imgs, len(imgs) - TARGET)\n",
        "        for f in remove:\n",
        "            f.unlink()\n",
        "        print(f\"{game.name}: reduced to {TARGET}\")\n",
        "    else:\n",
        "        print(f\"{game.name}: kept {len(imgs)}\")"
      ],
      "metadata": {
        "id": "vR5tVqbjabpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r frame_file.zip content/game_classifier/frames/*"
      ],
      "metadata": {
        "collapsed": true,
        "id": "todooFiRtYB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SPLIT_ROOT = os.path.join(dataset_dir)\n",
        "if os.path.exists(SPLIT_ROOT):\n",
        "    print(\"Dataset split root exists:\", SPLIT_ROOT)\n",
        "else:\n",
        "    os.makedirs(SPLIT_ROOT, exist_ok=True)\n",
        "\n",
        "def make_splits(frames_root, out_root, train_ratio=0.7, val_ratio=0.2):\n",
        "    for cls in os.listdir(frames_root):\n",
        "        src_dir = os.path.join(frames_root, cls)\n",
        "        files = sorted([str(p) for p in Path(src_dir).glob(\"*.jpg\")])\n",
        "        random.shuffle(files)\n",
        "        n = len(files)\n",
        "        if n == 0:\n",
        "            continue\n",
        "        n_train = int(n * train_ratio)\n",
        "        n_val = int(n * val_ratio)\n",
        "        train_files = files[:n_train]\n",
        "        val_files = files[n_train:n_train+n_val]\n",
        "        test_files = files[n_train+n_val:]\n",
        "        for split, flist in [(\"train\",train_files), (\"val\", val_files), (\"test\", test_files)]:\n",
        "            out_dir = os.path.join(out_root, split, cls)\n",
        "            os.makedirs(out_dir, exist_ok=True)\n",
        "            for src in flist:\n",
        "                dst = os.path.join(out_dir, os.path.basename(src))\n",
        "                shutil.copy2(src, dst)\n",
        "\n",
        "make_splits(frames_dir, SPLIT_ROOT)\n",
        "print(\"Created train/val/test in:\", SPLIT_ROOT)"
      ],
      "metadata": {
        "id": "zelrFOZsNI3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    os.path.join(SPLIT_ROOT, \"train\"),\n",
        "    image_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    seed=42, shuffle=True\n",
        ")\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    os.path.join(SPLIT_ROOT, \"val\"),\n",
        "    image_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    seed=42, shuffle=False\n",
        ")\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    os.path.join(SPLIT_ROOT, \"test\"),\n",
        "    image_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    seed=42, shuffle=False\n",
        ")\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(\"Classes:\", class_names)"
      ],
      "metadata": {
        "id": "cNR1sFj_Nleo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.06),\n",
        "    layers.RandomZoom(0.08),\n",
        "    layers.RandomContrast(0.08),\n",
        "])\n",
        "\n",
        "def prepare(ds, augment=False):\n",
        "    ds = ds.map(lambda x,y: (tf.image.resize(x, (IMG_SIZE, IMG_SIZE)), y),\n",
        "                num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    ds = ds.map(lambda x,y: (preprocess_input(x), y),\n",
        "                num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    if augment:\n",
        "        ds = ds.map(lambda x,y: (data_augmentation(x, training=True), y),\n",
        "                    num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    return ds.cache().prefetch(AUTOTUNE)\n",
        "\n",
        "\n",
        "train_ds_pre = prepare(train_ds, augment=True)\n",
        "val_ds_pre = prepare(val_ds, augment=False)\n",
        "test_ds_pre = prepare(test_ds, augment=False)"
      ],
      "metadata": {
        "id": "dXjQES_RN0SN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(class_names)\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False, input_shape=(IMG_SIZE,IMG_SIZE,3), weights='imagenet')\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = keras.Input(shape=(IMG_SIZE,IMG_SIZE,3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-4),\n",
        "    loss=loss_fn,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "a673xNIQN-K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "\n",
        "for _, y in train_ds.unbatch():\n",
        "    labels.append(y.numpy())\n",
        "\n",
        "labels = np.array(labels)\n",
        "EPOCH_HEAD = 5\n",
        "EPOCH_FINE = 8\n",
        "\n",
        "history_head = model.fit(train_ds_pre, validation_data=val_ds_pre, epochs=EPOCH_HEAD)\n",
        "base_model.trainable = True\n",
        "freeze_until = 200\n",
        "for layer in base_model.layers[:freeze_until]:\n",
        "    layer.trainable = False\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-5),\n",
        "    loss=loss_fn,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_ft = model.fit(train_ds_pre, validation_data=val_ds_pre, epochs=EPOCH_FINE)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "zIk44G0pOHiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(models_dir, exist_ok=True)\n",
        "model_path = os.path.join(models_dir, \"game_effnetb0.h5\")\n",
        "class_json = os.path.join(models_dir, \"class_names.json\")\n",
        "model.save(model_path)\n",
        "with open(class_json, \"w\") as f:\n",
        "    json.dump(class_names, f)\n",
        "\n",
        "print(\"Saved model to:\", model_path)\n",
        "print(\"Saved class names to:\", class_json)\n",
        "print(\"Class order:\", class_names)"
      ],
      "metadata": {
        "id": "Diap-YiETOSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "for images, labels in test_ds_pre:\n",
        "    preds = model.predict(images)\n",
        "    y_pred.extend(np.argmax(preds, axis=1).tolist())\n",
        "    y_true.extend(labels.numpy().tolist())\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "print(f\"Test accuracy: {acc*100:.2f}%\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names, zero_division=0))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=class_names, yticklabels=class_names, cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\");\n",
        "plt.ylabel(\"True\");\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CwUrx6gpOUpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DN5lOrtETqkr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}